# -*- coding: utf-8 -*-
"""VGGTesi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HZ0l3bp_NBZqVMepWmR6bqDfcgAJS3Yj
"""

#load the necessary libraries
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import numpy as np
import tensorflow as tf
from keras import callbacks
from keras import optimizers
from keras.engine import Model
from keras.layers import Dropout, Flatten, Dense
from keras.optimizers import Adam
from keras.applications import VGG16
from keras.datasets import cifar10
from keras.utils import to_categorical

#load the dataset and reshape its dimensons to a size which led to the best results in past experiments (150x150)

#load the training set (about 80% of the entire dataset)

train_datagen = ImageDataGenerator(rescale=1./255)
X_train = train_datagen.flow_from_directory(
        '.../TIROCINIO/train_okco',
        target_size=(150,150),
        batch_size=50,
        shuffle=False,
        class_mode="categorical"
    )

#load the test set (about 20% of the entire dataset). Images are different from ones of the training set

test_datagen = ImageDataGenerator(rescale=1./255)
X_test = train_datagen.flow_from_directory(
        '.../TIROCINIO/test_okc',
        target_size=(150,150),
        batch_size=50,
        shuffle=False,
        class_mode="categorical"
    )

#load the VGG16 model from Keras, without the top layers

base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))
base_model.summary()

#LAYERS FOR FEATURE EXTRACTION

flat1 = Flatten()(base_model.layers[-1].output)

# define new model
model = Model(inputs=base_model.inputs, outputs=flat1)

#LAYERS FOR CLASSIFICATION

# add new classifier layers

flat1 = Flatten()(base_model.layers[-1].output)
class1 = Dense(4096, activation='relu')(flat1)
output = Dense(7, activation='softmax')(class1)
# define new model
model = Model(inputs=base_model.inputs, outputs=output)

#Set all layers,except the last one to not trainable

for layer in model.layers[:-1]: layer.trainable=False

model.summary()

#compile the model

from tensorflow.keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy', metrics=['accuracy'])

#train the model

from sklearn.metrics import confusion_matrix
epochs=20
for i in range(epochs):

 model.fit(
  X_train,
  validation_data=X_test,
  epochs=1
 )

#confusion matrix and classification report calculated for training set

import numpy as np
from sklearn.metrics import confusion_matrix,classification_report
batch_size = X_test.batch_size
num_of_test_samples = X_test.samples
predictions = model.predict(X_test,  num_of_test_samples // batch_size+1)

y_pred2 = np.argmax(predictions, axis=1)

true_classes = X_test.classes
class_labels = list(X_test.class_indices.keys())   

print(class_labels)

print(confusion_matrix(X_test.classes, y_pred2))

report = classification_report(true_classes, y_pred2, target_names=class_labels)
print(report)

#confusion matrix and classification report calculated for test set

import numpy as np
from sklearn.metrics import confusion_matrix,classification_report
batch_size = X_train.batch_size
num_of_test_samples = X_train.samples
predictions = model.predict(X_train)

y_pred = np.argmax(predictions, axis=1)

true_classes = X_train.classes
class_labels = list(X_train.class_indices.keys())   

print(class_labels)

print(confusion_matrix(X_train.classes, y_pred))

report = classification_report(true_classes, y_pred, target_names=class_labels)
print(report)